{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam, SGD\n",
    "from torchsummary import summary\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_0630=[25,41,33,52,29,37,25,46,45,33,45,44,39,55]\n",
    "ID_1674=[48,67,57,91,51,59,69,73,66,66,64,65,67,75]\n",
    "ID_2961=[67,86,83,94,69,78,86,88,80,81,73,78,86,83]\n",
    "ID_3564=[85,104,89,106,86,90,100,102,96,95,84,94,92]\n",
    "ID_3856=[99,114,106,115,104,100,109,108,108,103,93,113,103,93]\n",
    "ID_6695=[109,118,108,124,118,108,115,114,115,112,100,124,111,101]\n",
    "ID_6729=[118,124,121,129,126,114,122,123,122,121,106,132,118,107]\n",
    "ID_7089=[126,130,132,134,132,140,129,130,130,152,113,142,125,113]\n",
    "ID_7371=[147,150,143,164,143,143,156,138,163,156,119,167,135,121]\n",
    "ID_7784=[150,161,161,176,168,146,160,156,164,166,125,170,168,131]\n",
    "ID_7884=[156,163,164,183,176,147,160,157,166,165,145,175,168,145]\n",
    "ID_8594=[159,167,168,183,183,150,161,162,165,167,147,178,168,148]\n",
    "ID_9327=[163,168,171,185,182,152,162,166,168,172,148,179,171,153]\n",
    "ID_9918=[167,164,175,193,183,153,164,169,171,179,149,179,174,157]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "waistDF = pickle.load( open( \"waist_final_10272800_new.pkl\", \"rb\" ))\n",
    "wristDF = pickle.load( open( \"wrist_final_10272800_new.pkl\", \"rb\" ))\n",
    "#otherDF = pickle.load( open( \"others.pkl\", \"rb\" ))\n",
    "wristdrivingDF = pickle.load( open( \"wrist_dirving_final_5200000.pkl\", \"rb\" ) )\n",
    "waistdrivingDF = pickle.load( open( \"waist_dirving_final_5200000.pkl\", \"rb\" ) )\n",
    "wristothersDF = pickle.load( open( \"wrist_others_final_5600000.pkl\", \"rb\" ) )\n",
    "waistothersDF = pickle.load( open( \"waist_others_final_5600000.pkl\", \"rb\" ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dataset class</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom torch.utils import data\\n\\n\\nclass Dataset(data.Dataset):\\n   \\n    def __init__(self, X1,X2,Y):\\n        'Initialization'\\n        self.X1 = X1\\n        self.X2 = X2\\n        self.Y = Y\\n\\n    def __len__(self):\\n        'Denotes the total number of samples'\\n        return len(self.X1)\\n   \\n    def __getitem__(self, index):\\n        'Generates one sample of data'\\n        # Select sample\\n        x1 = self.X1[index]\\n        x2 = self.X1[index]\\n        y = self.Y[index]\\n\\n        return x1,x2,y\\n        \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "   \n",
    "    def __init__(self, X1,X2,Y):\n",
    "        'Initialization'\n",
    "        self.X1 = X1\n",
    "        self.X2 = X2\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.X1)\n",
    "   \n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        x1 = self.X1[index]\n",
    "        x2 = self.X1[index]\n",
    "        y = self.Y[index]\n",
    "\n",
    "        return x1,x2,y\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "   \n",
    "    def __init__(self, X1,X2,Y):\n",
    "        'Initialization'\n",
    "        self.X1 = X1\n",
    "        self.X2 = X2\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.X1)\n",
    "   \n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        x1 = self.X1[index]\n",
    "        x2 = self.X2[index]\n",
    "        y = self.Y[index]\n",
    "\n",
    "        return x1,x2,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Extracting X train and Y train</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "XWrist = wristDF[['x','y','z']]\n",
    "YWrist = wristDF[['walk']]\n",
    "XWaist = waistDF[['x','y','z']]\n",
    "YWaist = waistDF[['walk']]\n",
    "\n",
    "XWaistDriving = waistdrivingDF[['x','y','z']]\n",
    "YWaistDriving = waistdrivingDF[['walk']]\n",
    "XWristDriving = wristdrivingDF[['x','y','z']]\n",
    "YWristDriving = wristdrivingDF[['walk']]\n",
    "\n",
    "XWaistothers = waistothersDF[['x','y','z']]\n",
    "YWaistothers = waistothersDF[['walk']]\n",
    "XWristothers = wristothersDF[['x','y','z']]\n",
    "YWristothers = wristothersDF[['walk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XWaistDriving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "###preprocessing data -1 to 1 ###\n",
    "XWrist = preprocessing.normalize(XWrist.values)\n",
    "#YWrist = wristDF[['walk']]\n",
    "XWaist = preprocessing.normalize(XWaist.values)\n",
    "#YWaist = waistDF[['walk']]\n",
    "\n",
    "XWaistDriving = preprocessing.normalize(XWaistDriving.values)\n",
    "#YWaistDriving = waistdrivingDF[['walk']]\n",
    "XWristDriving = preprocessing.normalize(XWristDriving.values)\n",
    "#YWristDriving = wristdrivingDF[['walk']]\n",
    "\n",
    "XWaistothers = preprocessing.normalize(XWaistothers.values)\n",
    "#YWaistothers = waistothersDF[['walk']]\n",
    "XWristothers = preprocessing.normalize(XWristothers.values)\n",
    "#YWristothers = wristothersDF[['walk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.79147176,  0.26281696, -0.55181492])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(XWrist)[57764]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Reshapping the data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX_train = XLabel.values.reshape(93063,100,3)\\nY_train = YLabel.values.reshape(93063,100,1)\\nXd_train = xd.values.reshape(48000,100,3)\\nYd_train = yd.values.reshape(48000,100,1)\\nXOther_train = otherDF\\nYOther_train = np.full((48000,100,1),0)\\n#Y_train = max(z) for z in Y_train\\n'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train = XLabel.values.reshape(98918,100,3)\n",
    "#Y_train = YLabel.values.reshape(98918,100,1)\n",
    "XWrist_train = XWrist.reshape(102728,100,3)\n",
    "YWrist_train = np.full((102728,100,1),1)\n",
    "XWaist_train = XWaist.reshape(102728,100,3)\n",
    "YWaist_train = np.full((102728,100,1),1)\n",
    "XWristDriving_train = XWristDriving.reshape(52000,100,3)\n",
    "YWristDriving_train = np.full((52000,100,1),0)\n",
    "XWaistDriving_train = XWaistDriving.reshape(52000,100,3)\n",
    "YWaistDriving_train = np.full((52000,100,1),0)\n",
    "XWristothers_train = XWristothers.reshape(56000,100,3)\n",
    "YWristothers_train = np.full((56000,100,1),0)\n",
    "XWaistothers_train = XWaistothers.reshape(56000,100,3)\n",
    "YWaistothers_train = np.full((56000,100,1),0)\n",
    "\n",
    "'''\n",
    "X_train = XLabel.values.reshape(93063,100,3)\n",
    "Y_train = YLabel.values.reshape(93063,100,1)\n",
    "Xd_train = xd.values.reshape(48000,100,3)\n",
    "Yd_train = yd.values.reshape(48000,100,1)\n",
    "XOther_train = otherDF\n",
    "YOther_train = np.full((48000,100,1),0)\n",
    "#Y_train = max(z) for z in Y_train\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XWrist_train[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56000, 100, 3)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XWaistothers_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102728, 100, 1)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YWrist_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_waist = np.concatenate([XWrist_train,XWristDriving_train,XWristothers_train])\n",
    "Y_train_waist = np.concatenate([YWrist_train,YWristDriving_train,YWristothers_train])\n",
    "X_train_wrist = np.concatenate([XWaist_train,XWaistDriving_train,XWaistothers_train])\n",
    "Y_train_wrist = np.concatenate([YWaist_train,YWaistDriving_train,YWaistothers_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210728, 100, 3)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_waist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210728, 100, 1)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_waist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210728, 100, 3)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_wrist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210728, 100, 1)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_wrist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210728"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_waist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210728"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_wrist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210728"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train_waist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210728"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train_wrist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_combine=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(X_train_waist)):\n",
    "    temp = []\n",
    "    temp.append(X_train_waist[i])\n",
    "    temp.append(X_train_wrist[i])\n",
    "    X_train_combine.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210728"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_combine = np.array(X_train_combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_combine=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(Y_train_waist)):\n",
    "    temp = []\n",
    "    temp.append(Y_train_waist[i])\n",
    "    temp.append(Y_train_wrist[i])\n",
    "    Y_train_combine.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210728"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train_combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_combine = np.array(Y_train_combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210728, 100, 3)\n",
      "(210728, 100, 1)\n",
      "(210728, 2, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_waist.shape)\n",
    "print(Y_train_waist.shape)\n",
    "print(Y_train_combine.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training, validation and test split</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#waist_train_x, waist_val_x, waist_train_y, waist_val_y = train_test_split(X_train_waist, Y_train_waist, test_size = 0.2,train_size=0.8)\n",
    "#print(waist_val_x.shape,waist_val_y.shape)\n",
    "#waist_test_x, waist_val_x, waist_test_y, waist_val_y = train_test_split(waist_val_x, waist_val_y, test_size = 0.5,train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(waist_train_x.shape,waist_train_y.shape)\n",
    "#print(waist_val_x.shape,waist_val_y.shape)\n",
    "#print(waist_test_x.shape,waist_test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63219, 2, 100, 3) (63219, 2, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "combine_train_x, combine_val_x, combine_y, combine_val_y = train_test_split(X_train_combine, Y_train_combine, test_size = 0.3,train_size=0.7)\n",
    "print(combine_val_x.shape,combine_val_y.shape)\n",
    "combine_test_x, combine_val_x, combine_test_y, combine_val_y = train_test_split(combine_val_x, combine_val_y, test_size = 2/3,train_size=1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147509, 2, 100, 3) (147509, 2, 100, 1)\n",
      "(42146, 2, 100, 3) (42146, 2, 100, 1)\n",
      "(21073, 2, 100, 3) (21073, 2, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "print(combine_train_x.shape,combine_y.shape)\n",
    "print(combine_val_x.shape,combine_val_y.shape)\n",
    "print(combine_test_x.shape,combine_test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "waist_train_x=[] \n",
    "waist_train_y=[]\n",
    "waist_val_x=[]\n",
    "waist_val_y=[]\n",
    "waist_test_x=[]\n",
    "waist_test_y=[]\n",
    "wrist_train_x=[] \n",
    "wrist_train_y=[]\n",
    "wrist_val_x=[]\n",
    "wrist_val_y=[]\n",
    "wrist_test_x=[]\n",
    "wrist_test_y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(combine_train_x)):\n",
    "    #temp = []\n",
    "    waist_train_x.append(combine_train_x[i][0])\n",
    "    wrist_train_x.append(combine_train_x[i][1])\n",
    "    \n",
    "for i in range (len(combine_y)):\n",
    "    #temp = []\n",
    "    waist_train_y.append(combine_y[i][0])\n",
    "    wrist_train_y.append(combine_y[i][1])\n",
    "    \n",
    "    \n",
    "for i in range (len(combine_val_x)):\n",
    "    #temp = []\n",
    "    waist_val_x.append(combine_val_x[i][0])\n",
    "    wrist_val_x.append(combine_val_x[i][1])\n",
    "    \n",
    "for i in range (len(combine_val_y)):\n",
    "    #temp = []\n",
    "    waist_val_y.append(combine_val_y[i][0])\n",
    "    wrist_val_y.append(combine_val_y[i][1])\n",
    "    \n",
    "    \n",
    "for i in range (len(combine_test_x)):\n",
    "    #temp = []\n",
    "    waist_test_x.append(combine_test_x[i][0])\n",
    "    wrist_test_x.append(combine_test_x[i][1])\n",
    "    \n",
    "for i in range (len(combine_test_y)):\n",
    "    #temp = []\n",
    "    waist_test_y.append(combine_test_y[i][0])\n",
    "    wrist_test_y.append(combine_test_y[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42146"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wrist_val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "waist_train_x=np.array(waist_train_x)\n",
    "waist_train_y=np.array(waist_train_y)\n",
    "waist_val_x=np.array(waist_val_x)\n",
    "waist_val_y=np.array(waist_val_y)\n",
    "waist_test_x=np.array(waist_test_x)\n",
    "waist_test_y=np.array(waist_test_y)\n",
    "wrist_train_x=np.array(wrist_train_x)\n",
    "wrist_train_y=np.array(wrist_train_y)\n",
    "wrist_val_x=np.array(wrist_val_x)\n",
    "wrist_val_y=np.array(wrist_val_y)\n",
    "wrist_test_x=np.array(wrist_test_x)\n",
    "wrist_test_y=np.array(wrist_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    " #waist_train_y == wrist_train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20672.800000000003"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "206728*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrist_train_x, wrist_val_x, wrist_train_y, wrist_val_y = train_test_split(X_train_wrist, Y_train_wrist, test_size = 0.2,train_size=0.8)\n",
    "#print(waist_val_x.shape,waist_val_y.shape)\n",
    "#wrist_test_x, wrist_val_x, wrist_test_y, wrist_val_y = train_test_split(wrist_val_x, wrist_val_y, test_size = 0.5,train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147509, 100, 3) (147509, 100, 1)\n",
      "(42146, 100, 3) (42146, 100, 1)\n",
      "(21073, 100, 3) (21073, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "print(waist_train_x.shape,waist_train_y.shape)\n",
    "print(waist_val_x.shape,waist_val_y.shape)\n",
    "print(waist_test_x.shape,waist_test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147509, 100, 3) (147509, 100, 1)\n",
      "(42146, 100, 3) (42146, 100, 1)\n",
      "(21073, 100, 3) (21073, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "print(wrist_train_x.shape,wrist_train_y.shape)\n",
    "print(wrist_val_x.shape,wrist_val_y.shape)\n",
    "print(wrist_test_x.shape,wrist_test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainWaist = waist_train_x.reshape(147509,1,100,3)\n",
    "Y_trainWaist = waist_train_y.reshape(147509,100)\n",
    "Y_trainWaist = np.array([max(z) for z in Y_trainWaist])\n",
    "\n",
    "\n",
    "X_valWaist = waist_val_x.reshape(42146,1,100,3)\n",
    "Y_valWaist = waist_val_y.reshape(42146,100)\n",
    "Y_valWaist = np.array([max(z) for z in Y_valWaist])\n",
    "\n",
    "#X_test = test_x.reshape(97459,1,100,3)\n",
    "#Y_test = test_y.reshape(97459,100)\n",
    "X_testWaist = waist_test_x.reshape(21073,1,100,3)\n",
    "Y_testWaist = waist_test_y.reshape(21073,100)\n",
    "Y_testWaist = np.array([max(z) for z in Y_testWaist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147509, 1, 100, 3) (147509,)\n",
      "(42146, 1, 100, 3) (42146,)\n",
      "(21073, 1, 100, 3) (21073,)\n"
     ]
    }
   ],
   "source": [
    "print(X_trainWaist.shape,Y_trainWaist.shape)\n",
    "print(X_valWaist.shape,Y_valWaist.shape)\n",
    "print(X_testWaist.shape,Y_testWaist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainWrist = wrist_train_x.reshape(147509,1,100,3)\n",
    "Y_trainWrist = wrist_train_y.reshape(147509,100)\n",
    "Y_trainWrist = np.array([max(z) for z in Y_trainWrist])\n",
    "\n",
    "\n",
    "X_valWrist = wrist_val_x.reshape(42146,1,100,3)\n",
    "Y_valWrist = wrist_val_y.reshape(42146,100)\n",
    "Y_valWrist = np.array([max(z) for z in Y_valWrist])\n",
    "\n",
    "#X_test = test_x.reshape(97459,1,100,3)\n",
    "#Y_test = test_y.reshape(97459,100)\n",
    "X_testWrist = waist_test_x.reshape(21073,1,100,3)\n",
    "Y_testWrist = waist_test_y.reshape(21073,100)\n",
    "Y_testWrist = np.array([max(z) for z in Y_testWrist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_trainWrist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_trainWaist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147509, 1, 100, 3) (147509,)\n",
      "(42146, 1, 100, 3) (42146,)\n",
      "(21073, 1, 100, 3) (21073,)\n"
     ]
    }
   ],
   "source": [
    "print(X_trainWrist.shape,Y_trainWrist.shape)\n",
    "print(X_valWrist.shape,Y_valWrist.shape)\n",
    "print(X_testWrist.shape,Y_testWrist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('splitdata/X_trainWristfinal_combine5', X_trainWrist) \n",
    "np.save('splitdata/Y_trainWristfinal_combine5', Y_trainWrist) \n",
    "np.save('splitdata/X_valWristfinal_combine5', X_valWrist) \n",
    "np.save('splitdata/Y_valWristfinal_combine5', Y_valWrist) \n",
    "np.save('splitdata/X_testWristfinal_combine5', X_testWrist) \n",
    "np.save('splitdata/Y_testWristfinal_combine5', Y_testWrist) \n",
    "\n",
    "\n",
    "np.save('splitdata/X_trainWaistfinal_combine5', X_trainWaist) \n",
    "np.save('splitdata/Y_trainWaistfinal_combine5', Y_trainWaist) \n",
    "np.save('splitdata/X_valWaistfinal_combine5', X_valWaist) \n",
    "np.save('splitdata/Y_valWaistfinal_combine5', Y_valWaist) \n",
    "np.save('splitdata/X_testWaistfinal_combine5', X_testWaist) \n",
    "np.save('splitdata/Y_testWaistfinal_combine5', Y_testWaist) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tensors</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainWaist = torch.from_numpy(X_trainWaist)\n",
    "Y_trainWaist = torch.from_numpy(Y_trainWaist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainWrist = torch.from_numpy(X_trainWrist)\n",
    "Y_trainWrist = torch.from_numpy(Y_trainWrist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([147509, 1, 100, 3]) torch.Size([147509, 1, 100, 3])\n"
     ]
    }
   ],
   "source": [
    "print(X_trainWaist.shape,X_trainWaist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([147509, 1, 100, 3]) torch.Size([147509, 1, 100, 3])\n"
     ]
    }
   ],
   "source": [
    "print(X_trainWrist.shape,X_trainWrist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valWaist = torch.from_numpy(X_valWaist)\n",
    "Y_valWaist = torch.from_numpy(Y_valWaist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([42146, 1, 100, 3]) torch.Size([42146])\n"
     ]
    }
   ],
   "source": [
    "print(X_valWaist.shape,Y_valWaist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valWrist = torch.from_numpy(X_valWrist)\n",
    "Y_valWrist = torch.from_numpy(Y_valWrist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([42146, 1, 100, 3]) torch.Size([42146])\n"
     ]
    }
   ],
   "source": [
    "print(X_valWrist.shape,Y_valWrist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testWaist = torch.from_numpy(X_testWaist)\n",
    "Y_testWaist = torch.from_numpy(Y_testWaist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21073, 1, 100, 3]) torch.Size([21073])\n"
     ]
    }
   ],
   "source": [
    "print(X_testWaist.shape,Y_testWaist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testWrist = torch.from_numpy(X_testWrist)\n",
    "Y_testWrist = torch.from_numpy(Y_testWrist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21073, 1, 100, 3]) torch.Size([21073])\n"
     ]
    }
   ],
   "source": [
    "print(X_testWrist.shape,Y_testWrist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([147509, 1, 100, 3])\n",
      "torch.Size([147509])\n"
     ]
    }
   ],
   "source": [
    "print(X_trainWaist.shape)\n",
    "print(Y_trainWaist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 64,'num_workers': 6}\n",
    "#params = {'batch_size': 256,'num_workers': 6}\n",
    "max_epochs = 10\n",
    "\n",
    "\n",
    "# Generators\n",
    "training_setCombine = Dataset(X_trainWaist, X_trainWrist, Y_trainWaist)\n",
    "training_generatorCombine = data.DataLoader(training_setCombine, **params)\n",
    "\n",
    "\n",
    "validation_setCombine = Dataset(X_valWaist,X_valWrist, Y_valWaist)\n",
    "validation_generatorCombine = data.DataLoader(validation_setCombine, **params)\n",
    "\n",
    "test_set = Dataset(X_testWaist,X_testWrist, Y_testWaist)\n",
    "testset_generatorCombine = data.DataLoader(test_set, **params)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.2039,  0.9790, -0.0058],\n",
       "          [ 0.2230,  0.9743, -0.0312],\n",
       "          [ 0.2543,  0.9665, -0.0361],\n",
       "          [ 0.2890,  0.9572, -0.0147],\n",
       "          [ 0.3061,  0.9518,  0.0192],\n",
       "          [ 0.2975,  0.9537,  0.0444],\n",
       "          [ 0.2792,  0.9582,  0.0624],\n",
       "          [ 0.2542,  0.9640,  0.0778],\n",
       "          [ 0.2345,  0.9687,  0.0808],\n",
       "          [ 0.2185,  0.9726,  0.0798],\n",
       "          [ 0.1980,  0.9772,  0.0768],\n",
       "          [ 0.1798,  0.9815,  0.0665],\n",
       "          [ 0.1598,  0.9859,  0.0500],\n",
       "          [ 0.1459,  0.9887,  0.0344],\n",
       "          [ 0.1250,  0.9914,  0.0383],\n",
       "          [ 0.1021,  0.9938,  0.0439],\n",
       "          [ 0.0706,  0.9961,  0.0537],\n",
       "          [ 0.0428,  0.9966,  0.0703],\n",
       "          [ 0.0070,  0.9949,  0.1008],\n",
       "          [-0.0504,  0.9892,  0.1375],\n",
       "          [-0.1194,  0.9759,  0.1827],\n",
       "          [-0.2170,  0.9549,  0.2029],\n",
       "          [-0.3023,  0.9277,  0.2192],\n",
       "          [-0.3341,  0.9083,  0.2519],\n",
       "          [-0.2857,  0.9212,  0.2640],\n",
       "          [-0.2050,  0.9439,  0.2590],\n",
       "          [-0.1068,  0.9616,  0.2526],\n",
       "          [ 0.0209,  0.9744,  0.2240],\n",
       "          [ 0.1842,  0.9739,  0.1323],\n",
       "          [ 0.3236,  0.9461,  0.0086],\n",
       "          [ 0.3719,  0.9227, -0.1017],\n",
       "          [ 0.3427,  0.9279, -0.1471],\n",
       "          [ 0.2797,  0.9480, -0.1519],\n",
       "          [ 0.2356,  0.9607, -0.1465],\n",
       "          [ 0.2096,  0.9677, -0.1397],\n",
       "          [ 0.2008,  0.9702, -0.1354],\n",
       "          [ 0.1985,  0.9721, -0.1250],\n",
       "          [ 0.1801,  0.9773, -0.1111],\n",
       "          [ 0.1511,  0.9835, -0.0996],\n",
       "          [ 0.1169,  0.9885, -0.0960],\n",
       "          [ 0.0829,  0.9921, -0.0942],\n",
       "          [ 0.0692,  0.9928, -0.0977],\n",
       "          [ 0.0808,  0.9912, -0.1047],\n",
       "          [ 0.1246,  0.9844, -0.1246],\n",
       "          [ 0.1805,  0.9722, -0.1493],\n",
       "          [ 0.2316,  0.9605, -0.1541],\n",
       "          [ 0.2580,  0.9556, -0.1422],\n",
       "          [ 0.2647,  0.9537, -0.1427],\n",
       "          [ 0.2532,  0.9585, -0.1311],\n",
       "          [ 0.2304,  0.9669, -0.1091],\n",
       "          [ 0.2260,  0.9699, -0.0903],\n",
       "          [ 0.2791,  0.9573, -0.0753],\n",
       "          [ 0.3879,  0.9195, -0.0637],\n",
       "          [ 0.5031,  0.8620, -0.0618],\n",
       "          [ 0.5904,  0.8054, -0.0526],\n",
       "          [ 0.6472,  0.7609, -0.0469],\n",
       "          [ 0.6796,  0.7328, -0.0339],\n",
       "          [ 0.6774,  0.7351, -0.0279],\n",
       "          [ 0.6501,  0.7597, -0.0184],\n",
       "          [ 0.6227,  0.7824,  0.0000],\n",
       "          [ 0.6063,  0.7951,  0.0163],\n",
       "          [ 0.6080,  0.7938,  0.0143],\n",
       "          [ 0.6299,  0.7767, -0.0070],\n",
       "          [ 0.6504,  0.7590, -0.0286],\n",
       "          [ 0.6491,  0.7601, -0.0288],\n",
       "          [ 0.5962,  0.8029,  0.0021],\n",
       "          [ 0.5056,  0.8611,  0.0540],\n",
       "          [ 0.3992,  0.9121,  0.0936],\n",
       "          [ 0.3076,  0.9457,  0.1048],\n",
       "          [ 0.2332,  0.9682,  0.0911],\n",
       "          [ 0.1868,  0.9805,  0.0618],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]]], dtype=torch.float64),\n",
       " tensor([[[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [-0.1974, -0.9632, -0.1824],\n",
       "          [-0.3840, -0.9184, -0.0959],\n",
       "          [-0.6380, -0.7648, -0.0898],\n",
       "          [-0.8372, -0.5083, -0.2016],\n",
       "          [-0.8964, -0.2346, -0.3761],\n",
       "          [-0.8560, -0.0905, -0.5089],\n",
       "          [-0.5431, -0.3172, -0.7775],\n",
       "          [-0.1529, -0.7812, -0.6053],\n",
       "          [ 0.1001, -0.9205, -0.3777],\n",
       "          [ 0.1797, -0.9438, -0.2774],\n",
       "          [ 0.1740, -0.9553, -0.2392],\n",
       "          [ 0.0794, -0.9633, -0.2563],\n",
       "          [-0.0651, -0.9546, -0.2907],\n",
       "          [-0.3100, -0.8892, -0.3364],\n",
       "          [-0.6480, -0.6896, -0.3232],\n",
       "          [-0.8527, -0.4891, -0.1834],\n",
       "          [-0.8742, -0.4805, -0.0699],\n",
       "          [-0.8313, -0.5548, -0.0327],\n",
       "          [-0.8004, -0.5938, -0.0822],\n",
       "          [-0.7351, -0.6677, -0.1179],\n",
       "          [-0.5905, -0.7939, -0.1449],\n",
       "          [-0.3589, -0.9253, -0.1224],\n",
       "          [-0.1516, -0.9828, -0.1052],\n",
       "          [-0.0411, -0.9981, -0.0454],\n",
       "          [-0.0228, -0.9931, -0.1154],\n",
       "          [-0.0660, -0.9942, -0.0850],\n",
       "          [-0.0985, -0.9906, -0.0953],\n",
       "          [-0.1224, -0.9781, -0.1684],\n",
       "          [-0.0869, -0.9590, -0.2699],\n",
       "          [-0.0087, -0.9516, -0.3072],\n",
       "          [ 0.1204, -0.9516, -0.2827],\n",
       "          [ 0.2405, -0.9480, -0.2085],\n",
       "          [ 0.3435, -0.9264, -0.1542],\n",
       "          [ 0.3785, -0.9107, -0.1653],\n",
       "          [ 0.3024, -0.9257, -0.2272],\n",
       "          [ 0.1747, -0.9361, -0.3054],\n",
       "          [-0.0373, -0.9590, -0.2810],\n",
       "          [-0.3648, -0.9082, -0.2055],\n",
       "          [-0.6307, -0.7520, -0.1918],\n",
       "          [-0.6975, -0.6772, -0.2344],\n",
       "          [-0.6520, -0.7215, -0.2330],\n",
       "          [-0.5777, -0.7841, -0.2267],\n",
       "          [-0.5330, -0.8261, -0.1830],\n",
       "          [-0.4808, -0.8687, -0.1189],\n",
       "          [-0.3803, -0.9222, -0.0697],\n",
       "          [-0.2709, -0.9602, -0.0685],\n",
       "          [-0.2234, -0.9698, -0.0976],\n",
       "          [-0.2413, -0.9566, -0.1631],\n",
       "          [-0.2753, -0.9187, -0.2833],\n",
       "          [-0.2185, -0.8538, -0.4726],\n",
       "          [-0.0796, -0.9129, -0.4005],\n",
       "          [ 0.2708, -0.7733, -0.5733],\n",
       "          [ 0.4468, -0.8295, -0.3351],\n",
       "          [ 0.5153, -0.7789, -0.3575],\n",
       "          [ 0.4864, -0.8143, -0.3168],\n",
       "          [ 0.3913, -0.8524, -0.3468],\n",
       "          [ 0.2544, -0.8479, -0.4652],\n",
       "          [ 0.0439, -0.7813, -0.6226],\n",
       "          [-0.1903, -0.6687, -0.7188],\n",
       "          [-0.2771, -0.6199, -0.7341],\n",
       "          [-0.2286, -0.7962, -0.5601],\n",
       "          [-0.0618, -0.9249, -0.3751],\n",
       "          [ 0.0357, -0.9613, -0.2733],\n",
       "          [ 0.0758, -0.9612, -0.2654],\n",
       "          [ 0.1160, -0.9451, -0.3055],\n",
       "          [ 0.1471, -0.9338, -0.3260],\n",
       "          [ 0.1255, -0.9254, -0.3576],\n",
       "          [ 0.0481, -0.9283, -0.3687],\n",
       "          [-0.0534, -0.9329, -0.3562],\n",
       "          [-0.1266, -0.9199, -0.3711],\n",
       "          [-0.1156, -0.9141, -0.3886],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]]], dtype=torch.float64),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_setCombine.__getitem__(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport torch\\nfrom torch.utils import data\\n\\n# CUDA for PyTorch\\nuse_cuda = torch.cuda.is_available()\\ndevice = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\\n\\n# Parameters\\nparams = {\\'batch_size\\': 64,\\'num_workers\\': 6}\\nmax_epochs = 10\\n\\n\\n# Generators\\ntraining_setWaist = Dataset(X_trainWaist, Y_trainWaist)\\ntraining_generatorWaist = data.DataLoader(training_setWaist, **params)\\n\\nvalidation_setWaist = Dataset(X_valWaist, Y_valWaist)\\nvalidation_generatorWaist = data.DataLoader(validation_setWaist, **params)\\n'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 64,'num_workers': 6}\n",
    "max_epochs = 10\n",
    "\n",
    "\n",
    "# Generators\n",
    "training_setWaist = Dataset(X_trainWaist, Y_trainWaist)\n",
    "training_generatorWaist = data.DataLoader(training_setWaist, **params)\n",
    "\n",
    "validation_setWaist = Dataset(X_valWaist, Y_valWaist)\n",
    "validation_generatorWaist = data.DataLoader(validation_setWaist, **params)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# CUDA for PyTorch\\nuse_cuda = torch.cuda.is_available()\\ndevice = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\\n\\n# Parameters\\nparams = {\\'batch_size\\': 64,\\'num_workers\\': 6}\\nmax_epochs = 10\\n\\n\\n# Generators\\ntraining_setWrist = Dataset(X_trainWrist, Y_trainWrist)\\ntraining_generatorWrist = data.DataLoader(training_setWrist, **params)\\n\\nvalidation_setWrist = Dataset(X_valWrist, Y_valWrist)\\nvalidation_generatorWrist = data.DataLoader(validation_setWrist, **params)\\n'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 64,'num_workers': 6}\n",
    "max_epochs = 10\n",
    "\n",
    "\n",
    "# Generators\n",
    "training_setWrist = Dataset(X_trainWrist, Y_trainWrist)\n",
    "training_generatorWrist = data.DataLoader(training_setWrist, **params)\n",
    "\n",
    "validation_setWrist = Dataset(X_valWrist, Y_valWrist)\n",
    "validation_generatorWrist = data.DataLoader(validation_setWrist, **params)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Building model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetWaist(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ConvNetWaist, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 128, kernel_size=(3,3), stride=1,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            #nn.Dropout(p=0.5),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "            \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=(3,3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(p=0.7),\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool2d(kernel_size=2, stride=2,padding=1))\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2,padding=1))\n",
    "        \n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=(3,3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(p=0.7),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        #self.fc1 = nn.Linear(100*2*4,64)\n",
    "        #self.fc2 = nn.Linear(64,1)\n",
    "        #self.fc1 = nn.Linear(100*2*4,64)\n",
    "        #self.fc2 = nn.Linear(64,2)\n",
    "       \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        #out = self.layer4(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        #out = F.relu(self.fc1(out))\n",
    "        #out = F.relu(self.fc1(out))\n",
    "        #out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetWrist(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ConvNetWrist, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 128, kernel_size=(3,3), stride=1,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            #nn.Dropout(p=0.5),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "            \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=(3,3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(p=0.7),\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool2d(kernel_size=2, stride=2,padding=1))\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2,padding=1))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=(3,3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(p=0.7),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        #self.fc1 = nn.Linear(100*2*4,64)\n",
    "        #self.fc2 = nn.Linear(64,1)\n",
    "        #self.fc1 = nn.Linear(100*2*4,64)\n",
    "        #self.fc2 = nn.Linear(64,2)\n",
    "       \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        #out = self.layer4(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        #out = F.relu(self.fc1(out))\n",
    "        #out = F.relu(self.fc1(out))\n",
    "        #out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Combine_Waist_Wrist(nn.Module):\n",
    "    def __init__(self, modelA, modelB):\n",
    "        super(Combine_Waist_Wrist, self).__init__()\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "        \n",
    "        self.fc1 = nn.Linear(100*2*4*2,64)\n",
    "        #self.fc1 = nn.Linear(100*2*2,64)\n",
    "        \n",
    "        self.classifier = nn.Linear(64,1)   ### 2 -> 1 , make labels 1 dimensions: 0 or 1\n",
    "        #linear layers\n",
    "        #linear layers\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.modelA(x1)\n",
    "        x2 = self.modelB(x2)\n",
    "        out = torch.cat((x1, x2), dim=1)\n",
    "        \n",
    "        out = F.relu(self.fc1(out))\n",
    "        #out = (self.fc1(out))\n",
    "        x = self.classifier(out)  # not relu\n",
    "        #x = F.tanh(out)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Combine_Waist_Wrist(\n",
       "  (modelA): ConvNetWaist(\n",
       "    (layer1): Sequential(\n",
       "      (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout(p=0.7, inplace=False)\n",
       "      (3): ReLU()\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout(p=0.7, inplace=False)\n",
       "      (3): ReLU()\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (modelB): ConvNetWrist(\n",
       "    (layer1): Sequential(\n",
       "      (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout(p=0.7, inplace=False)\n",
       "      (3): ReLU()\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout(p=0.7, inplace=False)\n",
       "      (3): ReLU()\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (fc1): Linear(in_features=1600, out_features=64, bias=True)\n",
       "  (classifier): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "modelWaist = ConvNetWaist()\n",
    "modelWrist = ConvNetWrist()\n",
    "modelCombine = Combine_Waist_Wrist(modelWaist,modelWrist)\n",
    "#model=model.Dropout(p=0.2)\n",
    "criterion = nn.MSELoss()\n",
    "#optimizerWaist = SGD(modelWaist.parameters(), lr=0.00001)\n",
    "#optimizerWrist = SGD(modelWrist.parameters(), lr=0.00001)\n",
    "#optimizerCombine = optimizerWaist +optimizerWrist\n",
    "\n",
    "params = list(modelWaist.parameters()) + list(modelWrist.parameters())\n",
    "optimizerCombine = SGD(params, lr=0.00001,weight_decay = 0.005)\n",
    "#scheduler = StepLR(optimizerCombine, step_size=1, gamma=0.9)\n",
    "#weight_decay=1e-5\n",
    "\n",
    "#optimizerCombine = SGD(modelCombine.parameters(), lr=0.001)\n",
    "#optimizer = SGD(model.parameters(), lr=0.01)\n",
    "#learning_rate = 0.01\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    #model = nn.DataParallel(model)\n",
    "    modelWaist = modelWaist.cuda()\n",
    "    modelWrist = modelWrist.cuda()\n",
    "    modelCombine = modelCombine.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "modelWaist.to(device)\n",
    "modelWrist.to(device)\n",
    "modelCombine.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 128, 100, 3]           1,280\n",
      "       BatchNorm2d-2          [-1, 128, 100, 3]             256\n",
      "              ReLU-3          [-1, 128, 100, 3]               0\n",
      "            Conv2d-4           [-1, 64, 100, 3]          73,792\n",
      "       BatchNorm2d-5           [-1, 64, 100, 3]             128\n",
      "           Dropout-6           [-1, 64, 100, 3]               0\n",
      "              ReLU-7           [-1, 64, 100, 3]               0\n",
      "         MaxPool2d-8            [-1, 64, 51, 2]               0\n",
      "            Conv2d-9            [-1, 32, 51, 2]          18,464\n",
      "      BatchNorm2d-10            [-1, 32, 51, 2]              64\n",
      "          Dropout-11            [-1, 32, 51, 2]               0\n",
      "             ReLU-12            [-1, 32, 51, 2]               0\n",
      "        MaxPool2d-13            [-1, 32, 25, 1]               0\n",
      "================================================================\n",
      "Total params: 93,984\n",
      "Trainable params: 93,984\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.62\n",
      "Params size (MB): 0.36\n",
      "Estimated Total Size (MB): 1.98\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(modelWaist, (1,100, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary(modelWrist, (1,100, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary(modelCombine, [(1,100, 3),(1,100, 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### how it will look like with new dataloader\n",
    "\n",
    "n_epochs = 50\n",
    "# empty list to store training losses\n",
    "#train_losses_waist = []\n",
    "#train_losses_wrist = []\n",
    "train_losses_combine = []\n",
    "train_losses_combine_avg = []\n",
    "\n",
    "# empty list to store validation losses\n",
    "#val_losses_waist = []\n",
    "#val_losses_wrist = []\n",
    "val_losses_combine = []\n",
    "val_losses_combine_avg = []\n",
    "\n",
    "def train():\n",
    "    modelCombine.train()\n",
    "    tr_loss = 0\n",
    "    \n",
    "    #n_epochs = 10\n",
    "    best_loss=99999999999999\n",
    "    for epoch in range(n_epochs):\n",
    "        tr_loss = 0\n",
    "        val_loss = 0\n",
    "        temp1=[]\n",
    "        temp2=[]\n",
    "        #scheduler.step()\n",
    "        for local_batch_waist, local_batch_wrist,local_labels in training_generatorCombine:\n",
    "            local_batch_waist, local_batch_wrist, local_labels = local_batch_waist.to(device), local_batch_wrist.to(device), local_labels.to(device)\n",
    "            #local_batch_waist, local_labels = local_batch_waist.to(device), local_labels.to(device)\n",
    "            \n",
    "            \n",
    "            optimizerCombine.zero_grad()\n",
    "            #optimizerWrist.zero_grad()\n",
    "            output_train = modelCombine(local_batch_waist.float(), local_batch_wrist.float())\n",
    "            #output_train = modelCombine(local_batch_waist.float())\n",
    "            loss_train = criterion(output_train, local_labels.unsqueeze(1).float())\n",
    "            \n",
    "            #print(local_labels)\n",
    "            #print(output_train)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #print(loss_train)\n",
    "\n",
    "            train_losses_combine.append(loss_train)\n",
    "            temp1.append(loss_train.item())\n",
    "            \n",
    "            loss_train.backward()\n",
    "            optimizerCombine.step()\n",
    "            tr_loss = loss_train.item()\n",
    "            #tr_loss = tr_loss + loss_train.item()\n",
    "        avg_loss = np.mean(temp1)\n",
    "        train_losses_combine_avg.append(avg_loss)\n",
    "        #print(tr_loss)\n",
    "        print('Epoch : ',epoch+1, '\\t', 'loss :', avg_loss)\n",
    "        #print('Epoch : ',epoch+1, '\\t', 'loss :', tr_loss)\n",
    "        \n",
    "        \n",
    "        with torch.set_grad_enabled(False):\n",
    "            for local_batch_waist, local_batch_wrist, local_labels in validation_generatorCombine:\n",
    "                #local_batch_waist, local_labels = local_batch_waist.to(device), local_labels.to(device)\n",
    "                local_batch_waist, local_batch_wrist, local_labels = local_batch_waist.to(device), local_batch_wrist.to(device), local_labels.to(device)\n",
    "                \n",
    "                output_val = modelCombine(local_batch_waist.float(),local_batch_wrist.float())\n",
    "                loss_val = criterion(output_val, local_labels.unsqueeze(1).float())\n",
    "                val_losses_combine.append(loss_val)\n",
    "                temp2.append(loss_val.item())\n",
    "                #val_loss = val_loss + loss_val\n",
    "            avg_loss = np.mean(temp2)\n",
    "            if (avg_loss<=best_loss):\n",
    "                torch.save(modelCombine.state_dict(), \"Sixth_Combine_best_epoch50.pt\")\n",
    "                best_loss=avg_loss\n",
    "                print(\"best:  \",best_loss)\n",
    "                # safe the best mode -> lowest validation loss\n",
    "            val_losses_combine_avg.append(avg_loss)\n",
    "            print('Epoch : ',epoch+1, '\\t', 'loss :', avg_loss)\n",
    "            \n",
    "            \n",
    "    \n",
    "\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  1 \t loss : 0.39549188233120064\n",
      "best:   0.29824045126373017\n",
      "Epoch :  1 \t loss : 0.29824045126373017\n",
      "Epoch :  2 \t loss : 0.2540112011086139\n",
      "best:   0.21429580121056624\n",
      "Epoch :  2 \t loss : 0.21429580121056624\n",
      "Epoch :  3 \t loss : 0.19703264511200455\n",
      "best:   0.17889936571327436\n",
      "Epoch :  3 \t loss : 0.17889936571327436\n",
      "Epoch :  4 \t loss : 0.1714165331226109\n",
      "best:   0.16460744265540417\n",
      "Epoch :  4 \t loss : 0.16460744265540417\n",
      "Epoch :  5 \t loss : 0.15852321906746597\n",
      "best:   0.1533018256649262\n",
      "Epoch :  5 \t loss : 0.1533018256649262\n",
      "Epoch :  6 \t loss : 0.14937376787566828\n",
      "best:   0.14552757215201403\n",
      "Epoch :  6 \t loss : 0.14552757215201403\n",
      "Epoch :  7 \t loss : 0.14186500973207572\n",
      "best:   0.14085205825263344\n",
      "Epoch :  7 \t loss : 0.14085205825263344\n",
      "Epoch :  8 \t loss : 0.1391534623865709\n",
      "best:   0.1364832344113062\n",
      "Epoch :  8 \t loss : 0.1364832344113062\n",
      "Epoch :  9 \t loss : 0.1359784685091445\n",
      "best:   0.13383396039964215\n",
      "Epoch :  9 \t loss : 0.13383396039964215\n",
      "Epoch :  10 \t loss : 0.13292543125256023\n",
      "best:   0.13128171473379743\n",
      "Epoch :  10 \t loss : 0.13128171473379743\n",
      "Epoch :  11 \t loss : 0.1301881803656219\n",
      "best:   0.12885667422110827\n",
      "Epoch :  11 \t loss : 0.12885667422110827\n",
      "Epoch :  12 \t loss : 0.12652503592073272\n",
      "best:   0.12657728326564854\n",
      "Epoch :  12 \t loss : 0.12657728326564854\n",
      "Epoch :  13 \t loss : 0.12633298393379322\n",
      "best:   0.12398621110932419\n",
      "Epoch :  13 \t loss : 0.12398621110932419\n",
      "Epoch :  14 \t loss : 0.12400095490597333\n",
      "best:   0.12183212623429769\n",
      "Epoch :  14 \t loss : 0.12183212623429769\n",
      "Epoch :  15 \t loss : 0.12272034376988959\n",
      "Epoch :  15 \t loss : 0.12381637624955322\n",
      "Epoch :  16 \t loss : 0.12092084808683189\n",
      "best:   0.11989753160834855\n",
      "Epoch :  16 \t loss : 0.11989753160834855\n",
      "Epoch :  17 \t loss : 0.11994432229508288\n",
      "best:   0.11953432976702096\n",
      "Epoch :  17 \t loss : 0.11953432976702096\n",
      "Epoch :  18 \t loss : 0.12032150469736526\n",
      "best:   0.11909329294253915\n",
      "Epoch :  18 \t loss : 0.11909329294253915\n",
      "Epoch :  19 \t loss : 0.11884874944896347\n",
      "best:   0.117361695495786\n",
      "Epoch :  19 \t loss : 0.117361695495786\n",
      "Epoch :  20 \t loss : 0.11739557871752603\n",
      "best:   0.1164104368690294\n",
      "Epoch :  20 \t loss : 0.1164104368690294\n",
      "Epoch :  21 \t loss : 0.11649361438645199\n",
      "best:   0.11534673788433553\n",
      "Epoch :  21 \t loss : 0.11534673788433553\n",
      "Epoch :  22 \t loss : 0.11567070189855362\n",
      "Epoch :  22 \t loss : 0.11631017947662763\n",
      "Epoch :  23 \t loss : 0.11536262256463024\n",
      "best:   0.1132175998708547\n",
      "Epoch :  23 \t loss : 0.1132175998708547\n",
      "Epoch :  24 \t loss : 0.11412095590908719\n",
      "Epoch :  24 \t loss : 0.11393254662952944\n",
      "Epoch :  25 \t loss : 0.1138085649354856\n",
      "best:   0.11278256041327087\n",
      "Epoch :  25 \t loss : 0.11278256041327087\n",
      "Epoch :  26 \t loss : 0.11286027327891027\n",
      "Epoch :  26 \t loss : 0.11398758224815085\n",
      "Epoch :  27 \t loss : 0.11273396670042564\n",
      "best:   0.1119913338303385\n",
      "Epoch :  27 \t loss : 0.1119913338303385\n",
      "Epoch :  28 \t loss : 0.11213170329266411\n",
      "best:   0.11098007236540951\n",
      "Epoch :  28 \t loss : 0.11098007236540951\n",
      "Epoch :  29 \t loss : 0.11070175498497718\n",
      "best:   0.10966682477044408\n",
      "Epoch :  29 \t loss : 0.10966682477044408\n",
      "Epoch :  30 \t loss : 0.11127508784484708\n",
      "best:   0.10901003892283338\n",
      "Epoch :  30 \t loss : 0.10901003892283338\n",
      "Epoch :  31 \t loss : 0.10975972460077797\n",
      "Epoch :  31 \t loss : 0.11003747970792882\n",
      "Epoch :  32 \t loss : 0.1098629288795584\n",
      "Epoch :  32 \t loss : 0.11044702690790022\n",
      "Epoch :  33 \t loss : 0.10883894554478744\n",
      "best:   0.10843877902477754\n",
      "Epoch :  33 \t loss : 0.10843877902477754\n",
      "Epoch :  34 \t loss : 0.10911473167369268\n",
      "best:   0.10747471712925365\n",
      "Epoch :  34 \t loss : 0.10747471712925365\n",
      "Epoch :  35 \t loss : 0.1081986801807896\n",
      "Epoch :  35 \t loss : 0.10892317641939125\n",
      "Epoch :  36 \t loss : 0.10721655628136854\n",
      "best:   0.10655643546753117\n",
      "Epoch :  36 \t loss : 0.10655643546753117\n",
      "Epoch :  37 \t loss : 0.10692978166286185\n",
      "best:   0.10617097979906115\n",
      "Epoch :  37 \t loss : 0.10617097979906115\n",
      "Epoch :  38 \t loss : 0.10630441942856265\n",
      "best:   0.1059134117354482\n",
      "Epoch :  38 \t loss : 0.1059134117354482\n",
      "Epoch :  39 \t loss : 0.10573760798916124\n",
      "best:   0.1052139903473836\n",
      "Epoch :  39 \t loss : 0.1052139903473836\n",
      "Epoch :  40 \t loss : 0.10522904284217612\n",
      "Epoch :  40 \t loss : 0.10579621974994995\n",
      "Epoch :  41 \t loss : 0.10416720436477868\n",
      "best:   0.10382564733870474\n",
      "Epoch :  41 \t loss : 0.10382564733870474\n",
      "Epoch :  42 \t loss : 0.1037727293669531\n",
      "Epoch :  42 \t loss : 0.10445352744350665\n",
      "Epoch :  43 \t loss : 0.10339983944455869\n",
      "best:   0.10333654793242221\n",
      "Epoch :  43 \t loss : 0.10333654793242221\n",
      "Epoch :  44 \t loss : 0.10338113388600163\n",
      "best:   0.10294530744210723\n",
      "Epoch :  44 \t loss : 0.10294530744210723\n",
      "Epoch :  45 \t loss : 0.10260273708664931\n",
      "best:   0.10203133447149455\n",
      "Epoch :  45 \t loss : 0.10203133447149455\n",
      "Epoch :  46 \t loss : 0.10196600803002359\n",
      "Epoch :  46 \t loss : 0.1022198666028441\n",
      "Epoch :  47 \t loss : 0.10191431990349888\n",
      "best:   0.10114145550271991\n",
      "Epoch :  47 \t loss : 0.10114145550271991\n",
      "Epoch :  48 \t loss : 0.10162133484303046\n",
      "best:   0.10086706574096123\n",
      "Epoch :  48 \t loss : 0.10086706574096123\n",
      "Epoch :  49 \t loss : 0.10163271432487929\n",
      "Epoch :  49 \t loss : 0.1012810917517484\n",
      "Epoch :  50 \t loss : 0.10070561631673587\n",
      "best:   0.0998981389046077\n",
      "Epoch :  50 \t loss : 0.0998981389046077\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n###### we tried this code\\n\\nn_epochs = 10\\n# empty list to store training losses\\n#train_losses_waist = []\\n#train_losses_wrist = []\\ntrain_losses_combine = []\\n\\n# empty list to store validation losses\\n#val_losses_waist = []\\n#val_losses_wrist = []\\nval_losses_combine = []\\n\\nmodelCombine.train()\\ntr_loss = 0\\noptimizerCombine.zero_grad()\\n\\nfor local_batch1, local_labels1 in training_generatorWaist:\\n    local_batch1, local_labels1 = local_batch1.to(device), local_labels1.to(device)\\n    \\n    for local_batch2, local_labels2 in training_generatorWrist:\\n        local_batch2, local_labels2 = local_batch2.to(device), local_labels2.to(device)\\n            \\n        output_train = modelCombine(local_batch1.float(), local_batch2.float())\\n        loss_train = criterion(output_train, local_labels1)\\n        \\n        train_losses_combine.append(loss_train)\\n\\n        loss_train.backward()\\n        optimizerCombine.step()\\n        tr_loss = loss_train.item()  \\n        \\n        \\n        break\\n        \\n    break\\n        \\n    '"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "###### we tried this code\n",
    "\n",
    "n_epochs = 10\n",
    "# empty list to store training losses\n",
    "#train_losses_waist = []\n",
    "#train_losses_wrist = []\n",
    "train_losses_combine = []\n",
    "\n",
    "# empty list to store validation losses\n",
    "#val_losses_waist = []\n",
    "#val_losses_wrist = []\n",
    "val_losses_combine = []\n",
    "\n",
    "modelCombine.train()\n",
    "tr_loss = 0\n",
    "optimizerCombine.zero_grad()\n",
    "\n",
    "for local_batch1, local_labels1 in training_generatorWaist:\n",
    "    local_batch1, local_labels1 = local_batch1.to(device), local_labels1.to(device)\n",
    "    \n",
    "    for local_batch2, local_labels2 in training_generatorWrist:\n",
    "        local_batch2, local_labels2 = local_batch2.to(device), local_labels2.to(device)\n",
    "            \n",
    "        output_train = modelCombine(local_batch1.float(), local_batch2.float())\n",
    "        loss_train = criterion(output_train, local_labels1)\n",
    "        \n",
    "        train_losses_combine.append(loss_train)\n",
    "\n",
    "        loss_train.backward()\n",
    "        optimizerCombine.step()\n",
    "        tr_loss = loss_train.item()  \n",
    "        \n",
    "        \n",
    "        break\n",
    "        \n",
    "    break\n",
    "        \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nn_epochs = 10\\n# empty list to store training losses\\n#train_losses_waist = []\\n#train_losses_wrist = []\\ntrain_losses_combine = []\\n\\n# empty list to store validation losses\\n#val_losses_waist = []\\n#val_losses_wrist = []\\nval_losses_combine = []\\n\\n\\n\\n\\n\\n\\ndef train():\\n    #model.train()\\n    #modelWaist.train()\\n    #modelWrist.train()\\n    modelCombine.train()\\n    tr_loss = 0\\n    #optimizerWrist.zero_grad()\\n    #optimizerWaist.zero_grad()\\n    optimizerCombine.zero_grad()\\n    #x_train, y_train = Variable(X_train), Variable(Y_train)\\n    #x_val, y_val = Variable(X_val), Variable(Y_val)\\n    for epoch in range(n_epochs):\\n        for local_batch, local_labels in training_generatorWaist:\\n            local_batch, local_labels = local_batch.to(device), local_labels.to(device)\\n            \\n            output_train = modelWaist(local_batch.float())\\n            loss_train = criterion(output_train, local_labels)\\n            train_losses_waist.append(loss_train)\\n\\n            loss_train.backward()\\n            optimizerWaist.step()\\n            tr_loss = loss_train.item()\\n\\n        print(tr_loss)\\n        print(\\'Epoch : \\',epoch+1, \\'\\t\\', \\'loss :\\', loss_train)\\n        \\n        \\n        for local_batch, local_labels in training_generatorWrist:\\n            local_batch, local_labels = local_batch.to(device), local_labels.to(device)\\n            \\n            output_train2 = modelWrist(local_batch.float())\\n            loss_train2 = criterion(output_train2, local_labels)\\n            train_losses_wrist.append(loss_train2)\\n\\n            loss_train2.backward()\\n            optimizerWrist.step()\\n            tr_loss = loss_train2.item()\\n\\n        print(tr_loss)\\n        print(\\'Epoch : \\',epoch+1, \\'\\t\\', \\'loss :\\', loss_train2)\\n        \\n        \\n        \\n        \\n        with torch.set_grad_enabled(False):\\n            for local_batch, local_labels in validation_generatorWaist:\\n            # Transfer to GPU\\n                local_batch, local_labels = local_batch.to(device), local_labels.to(device)\\n                \\n                output_val = modelWaist(local_batch.float())\\n                loss_val = criterion(output_val, local_labels)\\n                val_losses_waist.append(loss_val)\\n            print(\\'Epoch : \\',epoch+1, \\'\\t\\', \\'loss :\\', loss_val)\\n            \\n            for local_batch, local_labels in validation_generatorWrist:\\n            # Transfer to GPU\\n                local_batch, local_labels = local_batch.to(device), local_labels.to(device)\\n                \\n                output_val2 = modelWrist(local_batch.float())\\n                loss_val2 = criterion(output_val2, local_labels)\\n                val_losses_wrist.append(loss_val2)\\n            print(\\'Epoch : \\',epoch+1, \\'\\t\\', \\'loss :\\', loss_val2)\\n            \\n            \\n            \\n            \\n        #if(epoch==20):\\n        #    torch.save(model, \"10stepdatamodel_epoch20_3layers_2.pt\") \\n  '"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "n_epochs = 10\n",
    "# empty list to store training losses\n",
    "#train_losses_waist = []\n",
    "#train_losses_wrist = []\n",
    "train_losses_combine = []\n",
    "\n",
    "# empty list to store validation losses\n",
    "#val_losses_waist = []\n",
    "#val_losses_wrist = []\n",
    "val_losses_combine = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train():\n",
    "    #model.train()\n",
    "    #modelWaist.train()\n",
    "    #modelWrist.train()\n",
    "    modelCombine.train()\n",
    "    tr_loss = 0\n",
    "    #optimizerWrist.zero_grad()\n",
    "    #optimizerWaist.zero_grad()\n",
    "    optimizerCombine.zero_grad()\n",
    "    #x_train, y_train = Variable(X_train), Variable(Y_train)\n",
    "    #x_val, y_val = Variable(X_val), Variable(Y_val)\n",
    "    for epoch in range(n_epochs):\n",
    "        for local_batch, local_labels in training_generatorWaist:\n",
    "            local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "            \n",
    "            output_train = modelWaist(local_batch.float())\n",
    "            loss_train = criterion(output_train, local_labels)\n",
    "            train_losses_waist.append(loss_train)\n",
    "\n",
    "            loss_train.backward()\n",
    "            optimizerWaist.step()\n",
    "            tr_loss = loss_train.item()\n",
    "\n",
    "        print(tr_loss)\n",
    "        print('Epoch : ',epoch+1, '\\t', 'loss :', loss_train)\n",
    "        \n",
    "        \n",
    "        for local_batch, local_labels in training_generatorWrist:\n",
    "            local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "            \n",
    "            output_train2 = modelWrist(local_batch.float())\n",
    "            loss_train2 = criterion(output_train2, local_labels)\n",
    "            train_losses_wrist.append(loss_train2)\n",
    "\n",
    "            loss_train2.backward()\n",
    "            optimizerWrist.step()\n",
    "            tr_loss = loss_train2.item()\n",
    "\n",
    "        print(tr_loss)\n",
    "        print('Epoch : ',epoch+1, '\\t', 'loss :', loss_train2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        with torch.set_grad_enabled(False):\n",
    "            for local_batch, local_labels in validation_generatorWaist:\n",
    "            # Transfer to GPU\n",
    "                local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "                \n",
    "                output_val = modelWaist(local_batch.float())\n",
    "                loss_val = criterion(output_val, local_labels)\n",
    "                val_losses_waist.append(loss_val)\n",
    "            print('Epoch : ',epoch+1, '\\t', 'loss :', loss_val)\n",
    "            \n",
    "            for local_batch, local_labels in validation_generatorWrist:\n",
    "            # Transfer to GPU\n",
    "                local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "                \n",
    "                output_val2 = modelWrist(local_batch.float())\n",
    "                loss_val2 = criterion(output_val2, local_labels)\n",
    "                val_losses_wrist.append(loss_val2)\n",
    "            print('Epoch : ',epoch+1, '\\t', 'loss :', loss_val2)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        #if(epoch==20):\n",
    "        #    torch.save(model, \"10stepdatamodel_epoch20_3layers_2.pt\") \n",
    "  '''  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(modelWaist.state_dict(), \"sixth_Combine_last_epoch50.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Saving the model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(modelWaist, \"1Waist_stepdatamodel_epoch10_.pt\")\n",
    "#torch.save(modelWrist, \"1Wrist_stepdatamodel_epoch10_.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelCombine.load_state_dict(torch.load(\"Third_Combine_best_epoch25.pt\"))\n",
    "#modelWrist.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelWaist = torch.load(\"1Waist_stepdatamodel_epoch10_.pt\")\n",
    "#modelWaist.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Visualization of train and validation loss</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = open(\"splitdata/train_losses5_1.pkl\", 'wb')\n",
    "pickle.dump(train_losses_combine, loss1)\n",
    "loss1.close()\n",
    "loss2 = open(\"splitdata/val_losses5_1.pkl\", 'wb')\n",
    "pickle.dump(val_losses_combine, loss2)\n",
    "loss2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses_combine_avg, label='Training loss')\n",
    "plt.plot(val_losses_combine_avg, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#plt.savefig('CombineS_waist.png')\n",
    "#plt.savefig('Combine4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses_combine, label='Training loss')\n",
    "plt.plot(val_losses_combine, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#plt.savefig('Combines_waist.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Generating training accuracy</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#modelCombine = torch.load(\"1Combine_step_model_dropout0.8_weightdecay_scheduler_epoch10_last.pt\")\n",
    "#modelCombine.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntemp =[]\\nfor x in output:\\n    softmax = torch.exp(x).cpu()\\n    prob = list(softmax.numpy())\\n    temp.extend(prob)\\npredictions1 = np.argmax(temp, axis=1)\\n'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction for training set\n",
    "output =[]\n",
    "with torch.no_grad():\n",
    "    for local_batch_waist, local_batch_wrist, local_labels in training_generatorCombine:\n",
    "            #local_batch_waist, local_batch_wrist, local_labels = local_batch_waist.to(device), local_batch_wrist.to(device), local_labels.to(device)\n",
    "        output.append(modelCombine(local_batch_waist.float().cuda(), local_batch_wrist.float().cuda()))\n",
    "        \n",
    "#print(output[0])\n",
    "        \n",
    "\"\"\"\n",
    "temp =[]\n",
    "for x in output:\n",
    "    softmax = torch.exp(x).cpu()\n",
    "    prob = list(softmax.numpy())\n",
    "    temp.extend(prob)\n",
    "predictions1 = np.argmax(temp, axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(output[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions1.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5026484139749187"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_trainWrist, predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1,  ..., 1, 0, 0])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_trainWrist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Test set accuracy</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrist_count = pickle.load( open('wrist_count.pkl',\"rb\"))\n",
    "waist_count = pickle.load( open('waist_count.pkl',\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrist_count = np.array(wrist_count)\n",
    "waist_count = np.array(waist_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 100, 3)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(wrist_count[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.array(wrist_count[0]).reshape(240,1,100,3)\n",
    "#np.array(waist_count[0]).reshape(240,1,100,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_trainWaist = waist_train_x.reshape(144709,1,100,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ycount_test = np.full((240,100,1),1)\n",
    "Ycount_test = Ycount_test.reshape(240,100)\n",
    "Ycount_test = np.array([max(z) for z in Ycount_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ycount_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_countWaist = torch.from_numpy(np.array(wrist_count[15]).reshape(240,1,100,3))\n",
    "X_countWrist = torch.from_numpy(np.array(waist_count[15]).reshape(240,1,100,3))\n",
    "Ycount_test = torch.from_numpy(np.array(Ycount_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([240, 1, 100, 3])"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_countWrist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([240])"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ycount_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YWaist_train = np.full((102728,100,1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "params1 = {'batch_size': 20,'num_workers': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test_set = Dataset(X_countWaist,X_countWrist, Ycount_test)\n",
    "count_testset_generatorCombine = data.DataLoader(count_test_set, **params1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([240, 1, 100, 3])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_countWaist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_setCombine = Dataset(X_trainWaist, X_trainWrist, Y_trainWaist)\n",
    "#training_generatorCombine = data.DataLoader(training_setCombine, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-197-92c3c013f580>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mlocal_batch_waist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestset_generatorCombine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for local_batch_waist, local_labels in testset_generatorCombine:\n",
    "        print(local_labels)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'    \\ntemp =[]\\nfor x in output:\\n    softmax = torch.exp(x).cpu()\\n    prob = list(softmax.numpy())\\n    temp.extend(prob)\\npredictions3 = np.argmax(temp, axis=1)\\n'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction for training set\n",
    "output =[]\n",
    "prediction=[]\n",
    "count=0\n",
    "with torch.no_grad():\n",
    "    for local_batch_waist, local_batch_wrist, local_labels in testset_generatorCombine:\n",
    "        count=count+1\n",
    "            #local_batch_waist, local_batch_wrist, local_labels = local_batch_waist.to(device), local_batch_wrist.to(device), local_labels.to(device)\n",
    "        output.append(modelCombine(local_batch_waist.float().cuda(),local_batch_wrist.float().cuda()))\n",
    "        #output.append(modelWaist(local_batch.float().cuda()))\n",
    "        prediction.append(local_labels)\n",
    "        \n",
    "    print(count)        \n",
    "\"\"\"    \n",
    "temp =[]\n",
    "for x in output:\n",
    "    softmax = torch.exp(x).cpu()\n",
    "    prob = list(softmax.numpy())\n",
    "    temp.extend(prob)\n",
    "predictions3 = np.argmax(temp, axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = open(\"splitdata/prediction5_squeeze.pkl\", 'wb')\n",
    "pickle.dump(output, output2)\n",
    "output2.close()\n",
    "output2 = open(\"splitdata/label5_sqiueeze.pkl\", 'wb')\n",
    "pickle.dump(prediction, output2)\n",
    "output2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330\n",
      "7920 10185 644 2307\n"
     ]
    }
   ],
   "source": [
    "TP=0\n",
    "FP=0\n",
    "TN=0\n",
    "FN=0\n",
    "temp1=[]\n",
    "temp2=[]\n",
    "print(len(output))\n",
    "for i in range(0,(len(output)-1)):\n",
    "    pred=output[i]\n",
    "    labelset=prediction[i]\n",
    "    #print(pred)\n",
    "    #print(i)\n",
    "    for j in range(0,64):\n",
    "        #if(pred[j].item()!=0.5140):\n",
    "            #print('hello',pred[j].item())\n",
    "        #print(pred[j])\n",
    "        #print(labelset)\n",
    "        #for k in range(0,64):\n",
    "        temp1.append(pred[j].item())\n",
    "        temp2.append(labelset[j].item())\n",
    "        if (pred[j].item()>=0.5) and labelset[j].item()==1:\n",
    "            TP=TP+1\n",
    "        elif (pred[j].item()<0.5) and labelset[j].item()==1:\n",
    "            FN=FN+1\n",
    "        elif (pred[j].item()<0.5) and labelset[j].item()==0:\n",
    "            TN=TN+1\n",
    "        else:\n",
    "            FP=FP+1\n",
    "            \n",
    "print(TP,TN,FP,FN)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = open(\"splitdata/prediction5.pkl\", 'wb')\n",
    "pickle.dump(temp1, output2)\n",
    "output2.close()\n",
    "output2 = open(\"splitdata/label5.pkl\", 'wb')\n",
    "pickle.dump(temp2, output2)\n",
    "output2.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision = (TP/(TP+FP))\n",
    "Recall = (TP/(TP+FN))\n",
    "accuracy = (TP+TN)/(TP+FP+TN+FN)\n",
    "specificity = TN/(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9248014946286782\n",
      "0.7744206512173658\n",
      "0.8598499240121581\n",
      "0.940530058177117\n",
      "0.8429567346069927\n"
     ]
    }
   ],
   "source": [
    "print(Precision)\n",
    "print(Recall)\n",
    "print(accuracy)\n",
    "print(specificity)\n",
    "print(2*TP/(2*TP+FP+FN))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
